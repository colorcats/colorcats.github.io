<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>瞎捣鼓的废宅</title>
  <icon>https://www.gravatar.com/avatar/ef3b32cb12d3c073cf5aa79e7c76009c</icon>
  <subtitle>徘徊于虚幻与现实</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-03T15:18:00.975Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>colorcat</name>
    <email>color_cat@126.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>科创项目-视觉追踪系统</title>
    <link href="http://yoursite.com/2020/06/30/%E7%A7%91%E5%88%9B%E9%A1%B9%E7%9B%AE-%E8%A7%86%E8%A7%89%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F/"/>
    <id>http://yoursite.com/2020/06/30/%E7%A7%91%E5%88%9B%E9%A1%B9%E7%9B%AE-%E8%A7%86%E8%A7%89%E8%BF%BD%E8%B8%AA%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-06-30T03:57:54.000Z</published>
    <updated>2020-07-03T15:18:00.975Z</updated>
    
    <content type="html"><![CDATA[<h2 id="项目简介">项目简介</h2><p>​四月底开始接触这个项目，主要的目的是制作出一套能够实时采集<strong>瞳孔数据</strong>，通过<strong>数据分析</strong>得到注视点，最终呈现出来。</p><pre class="mermaid">graph LRA(摄像头采集双眼图像)-->B(图像预处理)B-->C(计算视线)C-->D(在环境图像中标注注视点)D-->A</pre><p>​整个项目在明年年中结项，最后的成果呈现预计要有一套完整硬件设备、配套算法以及各种测试数据。</p><p>​就我个人而言我对图像处理与数据分析部分更感兴趣，所以可能会主要做这方面的工作（项团内部至今还没有人员分工 😅）。</p><hr><h2 id="项目任务安排">项目任务安排</h2><p>​受疫情影响，一直不能回校。再加上五六月连着两个月考试，项团小组至今都没有独立讨论过项目进度安排。个人认为这并不是一个好开端，由于不了解其他人对整个项目的参与热情，也不便发起讨论。</p><p>​但总的来说，在返校前各自就项目所需进行知识学习肯定是首要的。返校后应该会尽快开展项目细节的讨论，确定项目的具体方案。</p><hr><h2 id="项目涉及技术">项目涉及技术</h2><h3 id="硬件">硬件</h3><p>​这部分主要包括电路中的控制部分与视觉采集部分，以及框架的建模。</p><p>​电路部分具体用什么控制，以及用什么方式与视觉采集部分相连还没有确定，但我目前是打算先用树莓派尝试编写算法（吃灰已久🌚）。因为要小型化，所以估计未来要上其他的单片机（到处都是知识盲区😂）。如果开学前我能把算法方面的东西学的差不多，可能也会试着学一下AD。</p><p>​框架的话，组里的两个学长好像比较擅长建模，估计会在其他部分设计完成后，由他们进行框架建模。</p><p>​但就技术难度而言，硬件这部分并不大，主要是<strong>明暗双目图像采集</strong>，以及<strong>环境图像采集</strong>，一共是三个摄像头。最主要的就是要实现三个摄像头的正常工作以及位置标定。</p><pre class="mermaid">graph LRA(硬件)-->B(电路/AD等)A-->C(框架/soildworks等)B-->D(采集图像信息)C-->E(方便携带以及标定位置)</pre><h3 id="软件">软件</h3><p>​这部分可以拓展的就比较多了。</p><p>​最基础的视觉追踪，需要能对明暗双目图像进行处理，得到瞳孔信息，通过数据处理得到视线方程。主要目标就是稳定、准确、快速。</p><pre class="mermaid">graph LRA(采集到的信息)---B(明暗双瞳图片)A---C(环境图片)B-->|数据分析/OpenCV| D(视线方程)D-->|标记注视点|C</pre><p>​目前而言我主要在学习图片的数据分析那部分，主要内容是图像处理的基础理论，以及OpenCV的各种API。</p><p>​如果可以完成上述的基础功能，应该还可以拓展出延申的应用。比如对注视点处的物体进行识别，并加以分析，呈现出相关信息，比如与测温模块结合，或许可以动态呈现注视点的温度信息。不过目前这还只是我的个人想法，如果基础的视觉追踪系统完成的比较早，或许可以考虑一下拓展的应用。</p><h2 id="进度">进度</h2><h3 id="团队状态">团队状态</h3><blockquote><p>四月底项团立项</p><p>五月初初次研讨，说明项团任务</p><p>受期末考试影响，至今还未再次研讨，处于各自学习的状态。</p></blockquote><h3 id="个人状态">个人状态</h3><blockquote><p>五月粗浅的学习了C++基础</p><p>六月开始学习图像处理理论基础，以及OpenCV的基础API</p><p>七月预计会完成OpenCV的基础课程，开始尝试针对项目需求进行程序编写(买成品红外摄像头好贵啊😭)</p></blockquote><h2 id="说明">说明</h2><p>我会动态更新这篇项目介绍博客，以及近期相关学习心得总结😄。</p><p>近期项目相关学习内容：<u>图像处理基础</u></p><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kity@2.0.4/dist/kity.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text/javascript" src="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/hexo-simple-mindmap@0.2.0/dist/mindmap.min.css">]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;项目简介&quot;&gt;项目简介&lt;/h2&gt;
&lt;p&gt;​		四月底开始接触这个项目，主要的目的是制作出一套能够实时采集&lt;strong&gt;瞳孔数据&lt;/strong&gt;，通过&lt;strong&gt;数据分析&lt;/strong&gt;得到注视点，最终呈现出来。&lt;/p&gt;
&lt;pre class=&quot;mermai
      
    
    </summary>
    
    
    
      <category term="科创项目" scheme="http://yoursite.com/tags/%E7%A7%91%E5%88%9B%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="计算机视觉" scheme="http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"/>
    
      <category term="动态更新" scheme="http://yoursite.com/tags/%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0/"/>
    
  </entry>
  
</feed>
